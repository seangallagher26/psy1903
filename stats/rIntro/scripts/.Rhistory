str(community_bias$WhiteImplicit)   # Numeric. Good!
# 2) There is a linear relationship between IV and DV (remember, we are doing *linear* regression!)
plot(WhiteImplicit ~ Segregation, data = community_bias,
main = "Scatterplot of Segregation and White Implicit Bias", las = 1)
qqnorm(community_bias$WhiteImplicit)
qqline(community_bias$WhiteImplicit)
# Let's fit the regression and assign the output of lm() to an object:
regression.output <- lm(WhiteImplicit ~ Segregation, data = community_bias)
View(regression.output)
# Add the least squares regression line from our fitted model
regLine(regression.output) # what is this line again?
# Add the least squares regression line from our fitted model
regLine(regression.output) # what is this line again?
if (!require("car")) {install.packages("car"); require("car")}  # for the regLine function
# Make the scatterplot again
plot(WhiteImplicit ~ Segregation, data = community_bias)
if (!require("car")) {install.packages("car"); require("car")}  # for the regLine function
# Add the least squares regression line from our fitted model
regLine(regression.output) # what is this line again?
# Make the scatterplot again
plot(WhiteImplicit ~ Segregation, data = community_bias)
# Add the least squares regression line from our fitted model
regLine(regression.output) # what is this line again?
summary(regression.output)
if (!require(car)) {install.packages("car"); require(car)}
## First you install the package.
install.packages("car")
## First you install the package.
install.packages("car")
install.packages("car")
## First you install the package.
install.packages("car")
install.packages("car")
if (!require(car)) {install.packages("car"); require(car)}
## First you install the package.
install.packages("car")
install.packages("car")
library(car)
require(car)
#  Loading the data:
community_bias <- read.csv("https://mair.sites.fas.harvard.edu/datasets/iatpolice.csv")
dim(community_bias)
# Inspect data object
head(community_bias)
str(community_bias)
#  What variables are in the dataset?
names(community_bias)
# Outcome variable (DV):
summary(community_bias$WhiteImplicit)
sd(community_bias$WhiteImplicit)
# Predictor variables (IVs):
summary(community_bias$Segregation)
sd(community_bias$Segregation)
summary(community_bias$Unemployment)
sd(community_bias$Unemployment)
summary(community_bias$PopulationDensity)
sd(community_bias$PopulationDensity)
# Outcome variable (DV):
hist(community_bias$WhiteImplicit)
# Predictor variables (IVs):
hist(community_bias$Segregation)
hist(community_bias$Unemployment)
hist(community_bias$PopulationDensity)
# dev.new() # if you run this line, plot will open in separate window; alternatively, you can click "Zoom" in the Plots panel on RStudio
scatterplotMatrix(~ WhiteImplicit + Segregation + Unemployment + PopulationDensity, data = community_bias)
# 1. The Dependent variable (the variable that is being predicted = y) is a metric variable:
str(community_bias$WhiteImplicit)
# a. HISTOGRAM: the OG method
hist(community_bias$WhiteImplicit, main = "White Implicit Bias", ylim = c(0, 50), breaks = 20) # Looks pretty normal.
# We can use qqnorm() to do a q-q plot of our DV and qqline() to draw the identity line y = x:
qqnorm(community_bias$WhiteImplicit)
qqline(community_bias$WhiteImplicit)
shapiro.test(community_bias$WhiteImplicit)
## We will use the following plot examine these initial assumptions 3 and 4 (listed above):
scatterplotMatrix(~ WhiteImplicit + Segregation + Unemployment + PopulationDensity, data = community_bias)
# Let's compute the multiple regression
regression.model <- lm(WhiteImplicit ~ Segregation + Unemployment + PopulationDensity, data = community_bias)
#  You can access the residuals like this:
residuals(regression.model)
#  Or like this:
regression.model$residuals
# 1. On average, the error term is 0 (i.e., E(εi) = 0)
mean(regression.model$residuals)
# For plotting purposes, standardize residuals (z-scores: mean = 0, var = 1 -- approximately)
resstd <- rstandard(regression.model)
resstd
# We can confirm that residuals are standardized, with mean=0 and variance=1
mean(resstd)
# We can confirm that residuals are standardized, with mean=0 and variance=1
mean(resstd)
var(resstd)
# Create scatterplot of fitted values as a function of the standardized residuals.
fitvals <- fitted(regression.model) ## Fitted (or predicted) values (on the regression plane)
fitvals
plot(fitvals, resstd, pch = 19, xlab = "Fitted Values", ylab = "Standardized Residuals")
abline(h = 0, lty = 2, col = "darkgray")
hist(resstd, main = "Histogram Residuals", xlab = "Standardized Residuals", breaks = 15)
qqnorm(resstd, main = "Q-Q Plot Residuals")
qqline(resstd)
shapiro.test(resstd)
## Model output:
summary(regression.model)
confint(regression.model)
confint(regression.model)
# Finally, plot the plane! Because why not - it's fancy!
if (!require("rockchalk")) {install.packages("rockchalk"); require("rockchalk")}
plotPlane(regression.model, plotx1 = "Segregation", plotx2 = "Unemployment")
plotPlane(regression.model, plotx1 = "Segregation", plotx2 = "PopulationDensity")
# Let's look at a new data set: "States" from the car package
states <- States
# Let's look at a new data set: "States" from the car package
states <- States
View(states)
output <- lm(SATV ~ dollars + pay + percent, data = states)
#lm(DV ~ IV1 + IV2 + IV3, data = NAME_OF_DATA_FRAME)
# 2. Which variables have a significant effect on SATV?
# Note: Don't rely on the *stars*!
output
#lm(DV ~ IV1 + IV2 + IV3, data = NAME_OF_DATA_FRAME)
# 2. Which variables have a significant effect on SATV?
# Note: Don't rely on the *stars*!
summary(output)
dollars <- lm(SATV ~ dollars, data = states)
sumamry(dollars)
summary(dollars)
pay <- lm(SATV ~ pay, data = states)
summary(pay)
percent <- lm(SATV ~ percent, data = states)
summary(percent)
confint(output)
resstd <- rstandard(output)
fitvals <- fitted(output)
#lm(DV ~ IV1 + IV2 + IV3, data = NAME_OF_DATA_FRAME)
# 2. Which variables have a significant effect on SATV?
# Note: Don't rely on the *stars*!
summary(output)
# 4. How much variance in SALARY (SATV) is accounted for by the combination of these 3 variables?
#.7392
var(output)
# 4. How much variance in SALARY (SATV) is accounted for by the combination of these 3 variables?
#.7392
var(resstd)
pokemon <- read.csv("Lab 9 pokemon speed.csv")
-------------------------------------------------------------------------------------------------------------------
if(!require(car)) {install.packages("car"); require(car)}
# if the above doesn't work for you:
install.packages("car")
require(car)
if (!require(car)) {install.packages("car"); require(car)} ## For data preparation
if (!require(vcd)) {install.packages("vcd"); require(vcd)} ## For visualizations
if (!require(pastecs)) {install.packages("pastecs"); require(pastecs)}  ## Utility functions descriptives
# Let's import the data:
resume <- read.csv("https://mair.sites.fas.harvard.edu/datasets/resume2.csv")
View(resume)
# The line below keeps just the two variables we're interested in.
# (This comes handy when we create the contingency tables).
resume <- resume[,c("race", "received_callback")]
View(resume)
table(resume$race) # exactly the same number of participants per race
table(resume$received_callback)
table(resume$received_callback)[2] / (table(resume$received_callback)[2] + table(resume$received_callback)[1])*100
racediscrim <- table(resume$received_callback, resume$race)
racediscrim #this table calculates each cell's absolute frequencies
margin.table(racediscrim)
prop.table(racediscrim) # a.k.a., relative frequencies
racediscrim/margin.table(racediscrim) #a.k.a., absolute frequencies divided by the total frequency
barplot(racediscrim, main = "Grouped Bar Chart", cex.names = 0.8, xlab = "Outcome",
legend.text = rownames(racediscrim), # This is an important line: "legend.text" equal to the row rownames(location)
beside = TRUE, # This is also an important line: it tells R to put the bar plots beside each other!
args.legend = list(x = "right", title = "Callback"))
mosaicplot(~ resume$race + resume$received_callback, main = "Mosaic racial discrimination",
xlab = "Race", ylab = "Outcome", col = "white")
# 1. We are comparing two categorical variables.
racediscrim # YES, both race and received_callback are variables with discrete categories.
# 2. Data in the cells should be frequencies, not percentages.
racediscrim # YES. The values here are frequencies (i.e., this is a frequency table)
resChi <- chisq.test(racediscrim)
View(resChi)
str(resChi)
resChi$expected #frequencies expected under the null, a.k.a., if the variables were independent
# Are expected cell frequencies >= 5?
resChi$expected >= 5 # YES!
resChi
resChi$expected # frequencies expected under the null, a.k.a., if the variables were independent
resChi$observed # frequencies observed in the data
resChi$residuals # residuals from the model
mosaicplot(~ resume$race + resume$received_callback, main = "Mosaic plot for race & callback",
xlab = "Race", ylab = "Callback", shade = TRUE)
load(url("https://mair.sites.fas.harvard.edu/datasets/IATstudy.rda"))
# Renaming the data set to be clearer:
Age_Bias_Study <- IATstudy
# - What is the mean implicit age bias (D_score) by Condition (Control, Statements, Pairings)?
by(Age_Bias_Study$D_Score, Age_Bias_Study$Condition, mean, na.rm=TRUE)
View(IATstudy)
# - What is the median implicit age bias (D_score) by Condition (Control, Statements, Pairings)?
by(Age_Bias_Study$D_Score, Age_Bias_Study$Condition, median, na.rm=TRUE)
# - Look at the range of implicit age bias (D_score) by Condition (Control, Statements, Pairings)?
by(Age_Bias_Study$D_Score, Age_Bias_Study$Condition, range, na.rm=TRUE)
# - Look at the standard deviation of implicit age bias (D_score) by Condition (Control, Statements, Pairings)?
by(Age_Bias_Study$D_Score, Age_Bias_Study$Condition, sd, na.rm=TRUE)
# Histogram of implicit age bias (D_Score) for each Condition (separate histogram for each Condition).
op <- par(mfrow = c(1,3))
hist(Age_Bias_Study$D_Score[Age_Bias_Study$Condition == "Control"], main = "Control", xlab = "Implicit Age Bias")
hist(Age_Bias_Study$D_Score[Age_Bias_Study$Condition == "Pairings"], main = "Pairings", xlab = "Implicit Age Bias")
hist(Age_Bias_Study$D_Score[Age_Bias_Study$Condition == "Statements"], main = "Statements", xlab = "Implicit Age Bias")
par(op)
# Box plot for the implicit age bias (D_Score) variable by condition:
boxplot(Age_Bias_Study$D_Score ~ Age_Bias_Study$Condition, main = "Implicit age bias by condition")
head(Age_Bias_Study$D_Score)
summary(Age_Bias_Study$Condition)
#Q-q plots
op <- par(mfrow = c(1, 3))
qqnorm(Age_Bias_Study$D_Score[Age_Bias_Study$Condition == "Control"])
qqline(Age_Bias_Study$D_Score[Age_Bias_Study$Condition == "Control"])
qqnorm(Age_Bias_Study$D_Score[Age_Bias_Study$Condition == "Pairings"])
qqline(Age_Bias_Study$D_Score[Age_Bias_Study$Condition == "Pairings"])
qqnorm(Age_Bias_Study$D_Score[Age_Bias_Study$Condition == "Statements"])
qqline(Age_Bias_Study$D_Score[Age_Bias_Study$Condition == "Statements"])
par(op
#Shapiro test
by(Age_Bias_Study$D_Score, Age_Bias_Study$Condition, shapiro.test)
#Shapiro test
by(Age_Bias_Study$D_Score, Age_Bias_Study$Condition, shapiro.test)
boxplot(Age_Bias_Study$D_Score ~ Age_Bias_Study$Condition, main = "Implicit age bias by condition")
#Q-q plots
op <- par(mfrow = c(1, 3))
#Shapiro test
by(Age_Bias_Study$D_Score, Age_Bias_Study$Condition, shapiro.test)
boxplot(Age_Bias_Study$D_Score ~ Age_Bias_Study$Condition, main = "Implicit age bias by condition")
leveneTest(Age_Bias_Study$D_Score ~ Age_Bias_Study$Condition)
myANOVA <- aov(D_Score ~ Condition, data = Age_Bias_Study)
summary(myANOVA)
summary(myANOVA)
if (!require(lsr)) {install.packages("lsr"); require(lsr)}
etaSquared(myANOVA)
View(myANOVA)
pairwise.t.test(Age_Bias_Study$D_Score, Age_Bias_Study$Condition, p.adj = "none") # correction for multiple comparisons not applied
pairwise.t.test(Age_Bias_Study$D_Score, Age_Bias_Study$Condition, p.adj = "holm") # correction for multiple comparisons applied
kruskal.test(Age_Bias_Study$D_Score ~ Age_Bias_Study$Condition)
if(!require(pgirmess)) {install.packages("pgirmess"); require(pgirmess)}
# Load the race IAT dataset:
#
#
load(url("https://mair.sites.fas.harvard.edu/datasets/raceIAT.rda"))
# Load the race IAT dataset:
#
#
load(url("https://mair.sites.fas.harvard.edu/datasets/raceIAT.rda"))
View(raceIAT)
# If you've done #2 correctly, you'll notice that there are a lot of cells with "0".
#
# This means that we will likely run into expected values < 5 or perhaps even 0.
# Recall that we can't compute a chi-squared test if you have expected values <1.
# AND at least 80% of the cells need to have expected values of 5 or larger.
#
# Using the ifelse() function, recode the race variable into a new variable called "race2" that has two levels: White and Other (i.e., nonWhite).
ifelse(raceIAT$race2 == 'White', 1, 0)
# Create the frequency table for race2 and gender, with gender as your column variable. Save it as an object called iat2.
iat2 <- table(race2 ~ gender, data = raceIAT)
# Create the frequency table for race2 and gender, with gender as your column variable. Save it as an object called iat2.
iat2 <- table(race2$gender)
# Create the frequency table for race2 and gender, with gender as your column variable. Save it as an object called iat2.
iat2 <- table(race2$gender, data = raceIAT)
# Create the frequency table for race2 and gender, with gender as your column variable. Save it as an object called iat2.
iat2 <- table(race2)
# Create the frequency table for race2 and gender, with gender as your column variable. Save it as an object called iat2.
iat2 <- table(raceIAT$gender)
# Create the frequency table for race2 and gender, with gender as your column variable. Save it as an object called iat2.
iat2 <- table(raceIAT$gender, raceIAT$race2)
if (!require(car)) {install.packages("car"); require(car)} # for Anova() function
if (!require(WRS2)) {install.packages("WRS2"); require(WRS2)} # for non-parametric 2-way ANOVA
# Load the data:
load(url("https://mair.sites.fas.harvard.edu/datasets/IATstudy.rda"))
implicit_bias <- IATstudy
# View your data. What are its dimensions?
View(implicit_bias)
# Let's quickly check the levels in our IVs
levels(implicit_bias$Condition) ## 3 levels
levels(implicit_bias$Ideology) ## 7 levels!!!
### IV1 - CONDITION:
# for simplicity let's only compare the control group and the Pairings intervention:
implicit_bias <- implicit_bias[implicit_bias$Condition %in% c("Control", "Pairings"), ]
View(implicit_bias)
implicit_bias$Condition <- droplevels(implicit_bias$Condition) ## don't forget to drop the unused level ("statements")
dim(implicit_bias)
table(implicit_bias$Condition) ## Nice and balanced
# the "within()" function below allows us to create a new variable with the releveled variable based on the
# values of the original "Ideology" variable:
implicit_bias <- within(implicit_bias, {
Ideology_releveled <- NA
Ideology_releveled[Ideology %in% c("Strongly conservative","Moderately conservative", "Slightly conservative")] <- "Conservative"
Ideology_releveled[Ideology %in% c("Strongly liberal","Moderately liberal", "Slightly liberal")] <- "Liberal"
Ideology_releveled[Ideology == "Neutral"] <- "Neutral"
})
load(url("https://mair.sites.fas.harvard.edu/datasets/IATstudy.rda"))
implicit_bias <- IATstudy
# View your data. What are its dimensions?
View(implicit_bias)
### b. Establishing the research question and hypotheses -------------------------------------------------------------------
## Our research question:
## Does political ideology impact the extent to which an intervention impacts anti-age bias?
## Our variables of interest:
# IV1: Condition -- (control, pairings) (we are going to drop the statements group)
# IV2: Ideology
# DV: D_score -- positive D scores indicating a anti-old bias, negative score indicates anti-young bias
# There are three main research questions we can ask of these data.
# Hint: Main effects vs. interactions.
# What are the research questions? Define null and alternative hypotheses for each question.
## Hypotheses:
# Main Effect (Condition):
# H0: The mean D_score is the same across conditions
# H1: The mean D_score is different across conditions
# Main Effect (Ideology):
# H0: The mean D_score is the same across ideologies
# H1: The mean D_score is different across ideologies
# Interaction Effect (Condition x Ideology):
# H0: The effect of condition on D_score doesn't change based on ideology (or the reverse)
# H1: The effect of condition on D_score changes based on ideology (or the reverse)
### c. Data Preparation: Re-leveling -------------------------------------------------------------------
# Let's quickly check the levels in our IVs
levels(implicit_bias$Condition) ## 3 levels
levels(implicit_bias$Ideology) ## 7 levels!!!
# Before we fit the model, let's reduce the number of levels in each of our IVs.
# Why is this important? Hint: think of all possible interactions...
### IV1 - CONDITION:
# for simplicity let's only compare the control group and the Pairings intervention:
implicit_bias <- implicit_bias[implicit_bias$Condition %in% c("Control", "Pairings"), ]
implicit_bias$Condition <- droplevels(implicit_bias$Condition) ## don't forget to drop the unused level ("statements")
dim(implicit_bias)
table(implicit_bias$Condition) ## Nice and balanced
Ideology_releveled <- NA
# the "within()" function below allows us to create a new variable with the releveled variable based on the
# values of the original "Ideology" variable:
implicit_bias <- within(implicit_bias, {
Ideology_releveled <- NA
Ideology_releveled[Ideology %in% c("Strongly conservative","Moderately conservative", "Slightly conservative")] <- "Conservative"
Ideology_releveled[Ideology %in% c("Strongly liberal","Moderately liberal", "Slightly liberal")] <- "Liberal"
Ideology_releveled[Ideology == "Neutral"] <- "Neutral"
})
# let's save scale as factor:
implicit_bias$Ideology_releveled <- factor(implicit_bias$Ideology_releveled)
# Let's check it worked:
View(implicit_bias)
# Now let's check how many observations we have per each level of our new Ideology_releveled variable:
table(implicit_bias$Ideology_releveled)
# Look at the mean, median, and SD of D_score in each cell (split by condition and ideology):
by(implicit_bias$D_Score, list(implicit_bias$Condition, implicit_bias$Ideology_releveled), mean)
by(implicit_bias$D_Score, list(implicit_bias$Condition, implicit_bias$Ideology_releveled), median)
by(implicit_bias$D_Score, list(implicit_bias$Condition, implicit_bias$Ideology_releveled), sd)
# Generate a box plot with all cells displayed on the same plot.
# - Don't forget to add a title: "D_score by condition × Ideology"
# - Trick: Instead of using just one variable, use IV * IV after the ~
boxplot(implicit_bias$D_Score ~ implicit_bias$Condition*implicit_bias$Ideology_releveled,
cex.axis = 0.7,
xlab = "Condition x Ideology",
ylab = "anti-age bias (D_score)",
main = "D_score by condition × ideology")
op <- par(mfrow = c(1,2))
# x-axis: Condition, line color: Ideology
interaction.plot(implicit_bias$Condition, implicit_bias$Ideology_releveled, implicit_bias$D_Score, ylab = "D_Score (anti-old bias)",
xlab = "Condition", type = "b", pch = 19, lty = 1, legend = FALSE, col = rainbow(5)[1:3])
legend("bottomleft", legend = c("Neutral", "Liberal", "Conservative"), lty = 1, col = rainbow(5)[1:3], cex = 0.6)
interaction.plot(implicit_bias$Ideology_releveled, implicit_bias$Condition, implicit_bias$D_Score, ylab = "D_Score (anti-old bias)",
xlab = "Ideology", type = "b", pch = 19, lty = 1, legend = FALSE, col = rainbow(5)[4:5])
legend("bottomleft", legend = c("Control", "Invervention (pairings)"), col = rainbow(5)[4:5], lty = 1, cex = 0.6)
par(op)
## DV: D_scores
head(implicit_bias$D_Score)
## IV1 - CONDITION:
summary(implicit_bias$Condition)
## IV1 - CONDITION:
summary(implicit_bias$Ideology_releveled)
# (5): Variance homogeneity (homoscedasticity)
# We can still use the leveneTest() function, as we did with one-way ANOVA,
# but now we need to adjust the arguments slightly: We add the interaction argument
leveneTest(implicit_bias$D_Score, interaction(implicit_bias$Ideology_releveled, implicit_bias$Condition))
## Which cell might be causing this effect? Why?
boxplot(implicit_bias$D_Score ~  implicit_bias$Condition*implicit_bias$Ideology_releveled, main = "D_score by Condition")
table(implicit_bias$Ideology_releveled, implicit_bias$Condition) # we don't have that many people in each group...
## For one-way ANOVA we used the aov() function
D_score_ANOVA <- aov(D_Score ~ Condition*Ideology_releveled, data = implicit_bias)
summary(D_score_ANOVA)
## BUT recall -- was the design balanced?
table(implicit_bias$Condition, implicit_bias$Ideology_releveled) ## No!
## SO -- we get different results than from above if we flip Condition and Ideology
D_score_ANOVA2 <- aov(D_Score ~ Ideology_releveled*Condition, data = implicit_bias)
## SO -- we get different results than from above if we flip Condition and Ideology
D_score_ANOVA2 <- aov(D_Score ~ Ideology_releveled*Condition, data = implicit_bias)
summary(D_score_ANOVA2) ## we need to address this!
ANOVA_adj <- Anova(D_score_ANOVA, type = "II", white.adjust = TRUE)
ANOVA_adj
# (4) IV is Normally distributed within each group: using the residuals to evaluate this assumption
stres <- rstandard(D_score_ANOVA)    ## extract standardized residuals
# Histogram & Q-Q plot
op <- par(mfrow = c(1,2))
# Histogram & Q-Q plot
op <- par(mfrow = c(1,2))
hist(stres, xlab = "Standardized Residuals", main = "Histogram Standardized Residuals")
qqnorm(stres)
qqline(stres)
par(op)
# Normality test on residuals
shapiro.test(stres)
ks.test(stres, "pnorm")
ANOVA_adj ## remember we had to adjust due to the unbalanced design.
interaction.plot(implicit_bias$Condition, implicit_bias$Ideology_releveled, implicit_bias$D_Score, ylab = "D_Score (anti-old bias)",
xlab = "Condition", type = "b", pch = 19, lty = 1, legend = FALSE, col = rainbow(5)[1:3])
legend("bottomleft", legend = c("Neutral", "Liberal", "Conservative"), lty = 1, col = rainbow(5)[1:3], cex = 0.6)
interaction.plot(implicit_bias$Condition, implicit_bias$Ideology_releveled, implicit_bias$D_Score, ylab = "D_Score (anti-old bias)",
xlab = "Condition", type = "b", pch = 19, lty = 1, legend = FALSE, col = rainbow(5)[1:3])
legend("bottomleft", legend = c("Neutral", "Liberal", "Conservative"), lty = 1, col = rainbow(5)[1:3], cex = 0.6)
## Plots of the main effects:
op <- par(mfrow = c(1,2))
boxplot(implicit_bias$D_Score ~  implicit_bias$Condition, main = "D_score by Condition")
boxplot(implicit_bias$D_Score ~  implicit_bias$Ideology_releveled, main = "D_score by Ideology")
par(op)
## reminder of all possible pairings:
boxplot(implicit_bias$D_Score ~  implicit_bias$Condition*implicit_bias$Ideology_releveled, main = "D_score by Condition")
par(op)
## reminder of all possible pairings:
boxplot(implicit_bias$D_Score ~  implicit_bias$Condition*implicit_bias$Ideology_releveled, main = "D_score by Condition")
# Pairwise comparisons:
TukeyHSD(D_score_ANOVA)   ## All pairwise post-hoc tests
## interaction plot involving the medians (!), and not the means.
op <- par(mfrow = c(1,2))
interaction.plot( implicit_bias$Condition,implicit_bias$Ideology_releveled, implicit_bias$D_Score,
fun = median, ylab = "Median D_score", type = "b", pch = 19,
lty = 1, col = 1:3, main = "Interaction Plot", legend = FALSE, xlab = "Condition")
legend("bottomleft", legend = c("Neurtal", "Liberal","Conservative"), col = 1:3, lty = 1, cex = 0.8)
interaction.plot(implicit_bias$Ideology_releveled, implicit_bias$Condition, implicit_bias$D_Score,
fun = median, ylab = "Median D_score", type = "b", pch = 19,
lty = 1, col = 1:2, main = "Interaction Plot", legend = FALSE, xlab = "Ideology")
legend("bottomleft", legend = c("Control", "Pairings"), col = 1:2, lty = 1, cex = 0.8)
par(op)
## Note: no need to worry about unbalanced designs in the non-parametric version
np_2way_aov <- med2way(D_Score ~ Condition*Ideology_releveled, data = implicit_bias)
np_2way_aov
## Non-parametric post-hoc tests:
mcp2a(D_Score ~ Condition*Ideology_releveled, data = implicit_bias)
# (1) Load the data into a new object called "myIAT"
# URL: https://mair.sites.fas.harvard.edu/datasets/raceideolIAT.csv
# No need to specify the "header" or "sep" arguments.
myIAT <- read.csv(https://mair.sites.fas.harvard.edu/datasets/raceideolIAT.csv)
# (1) Load the data into a new object called "myIAT"
# URL: https://mair.sites.fas.harvard.edu/datasets/raceideolIAT.csv
# No need to specify the "header" or "sep" arguments.
myIAT <- read.csv(https:/mair.sites.fas.harvard.edu/datasets/raceideolIAT.csv)
# (1) Load the data into a new object called "myIAT"
# URL: https://mair.sites.fas.harvard.edu/datasets/raceideolIAT.csv
# No need to specify the "header" or "sep" arguments.
myIAT <- read.csv(mair.sites.fas.harvard.edu/datasets/raceideolIAT.csv)
# (1) Load the data into a new object called "myIAT"
# URL: https://mair.sites.fas.harvard.edu/datasets/raceideolIAT.csv
# No need to specify the "header" or "sep" arguments.
myIAT <- read.csv(https://mair.sites.fas.harvard.edu/datasets/raceideolIAT.csv)
# First, let's load the packages.
if (!require(car)) {install.packages("car"); require(car)} # for Anova() function
if (!require(WRS2)) {install.packages("WRS2"); require(WRS2)} #
# (1) Load the data into a new object called "myIAT"
# URL: https://mair.sites.fas.harvard.edu/datasets/raceideolIAT.csv
# No need to specify the "header" or "sep" arguments.
myIAT <- read.csv("https://mair.sites.fas.harvard.edu/datasets/raceideolIAT.csv")
# (1) Load the data into a new object called "myIAT"
# URL: https://mair.sites.fas.harvard.edu/datasets/raceideolIAT.csv
# No need to specify the "header" or "sep" arguments.
myIAT <- read.csv("https://mair.sites.fas.harvard.edu/datasets/raceideolIAT.csv")
View(myIAT)
table(myIAT$ideol, myIAT$race)
by(myIAT$D, list(myIAT$ideol, myIAT$racd), mean)
by(myIAT$D, list(myIAT$ideol, myIAT$race), mean)
boxplot(myIAT$D~ myIAT$ideol*myIAT$race)
fitfacaov <- aov(D ~ ideol*race, data = myIAT)
summary(fitfacaov)
summary(fitfacaov)
?ifelse
?mutate
if(!require("fastDummies")) {install.packages("fastDummies"); require("fastDummies")}
?mutate
library("fastDummies")
if(!require("fastDummies")) {install.packages("fastDummies"); require("fastDummies")}
?mutate
?mutate
??mutate
if(!require("fastDummies")) {install.packages("fastDummies"); require("fastDummies")}
?dummy_cols
View(myIAT)
View(fitfacaov)
## Start by setting your working directory to your psy1903 folder. Replace "~/Desktop/" with the correct path to your psy1903 directory:
setwd("~/Desktop/psy1903/")
## Create a new parent directory called "stats" where we will be doing all of our R work:
dir.create("stats/")
## Create a new directory called "rIntro" for today's exercises:
dir.create("stats/rIntro")
## Create a new subdirectories "data", "scripts", & "output" for today's exercises:
dir.create("stats/rIntro/data")
dir.create("stats/rIntro/scripts")
dir.create("stats/rIntro/output")
## Set working directory to the rIntro/scripts parent directory, which will be our home base for today:
setwd("~/Desktop/psy1903/stats/rIntro/scripts")
## Save this script as R_introduction.R within your scripts directory
install.packages("ggplot2")
library("ggplot2")
if (!require("pacman")) {install.packages("pacman"); require("pacman")}  # First install and load in pacman to R
## Then use p_load and a list of all of the packages that you need for the project (with each one being in "quotes")
p_load("tidyverse","rstudioapi","lme4","emmeans","psych","corrplot")  # tidyverse contains many packages like dplyr, tidyr, stringr, and ggplot2, among others, and the additional packages should cover our data manipulations, plotting, and analyses
mydata <- read.csv("~/Desktop/psy1903/stats/rIntro/data/data.csv")
View(mydata)
mydata <- read.csv("~/Desktop/psy1903/stats/rIntro/data/data.csv", header = TRUE, stringsAsFactors = FALSE, na.strings = c("NA", "?"))
head(mydata)      # View the first few rows
str(mydata)       # See the structure of the data frame
mydata$moodGroup < as.factor(mydata$moodGroup)
mydata$moodGroup <- as.factor(mydata$moodGroup)
